
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>郑拓铭博客</title>
  <meta name="author" content="TuomingZheng">

  
  <meta name="description" content="
">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://TuomingZheng.github.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="郑拓铭博客" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">郑拓铭博客</a></h1>
  
    <h2>记忆、学习、思索、积累</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:TuomingZheng.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/13/picassoyuan-ma-jie-xi-zhi-cache/">Picasso源码解析之Cache</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-13T23:56:06+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/12/sqlite3zhi-writeaheadlogging/">SQLite3之WriteAheadLogging</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-12T01:54:43+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>SQLite3 引入了一个十分显眼的机制write-ahead logging机制，该机制相对于原先的logging机制
可以更高程度的支持数据库并发操作，在数据库操作过程中涉及到更少量的IO操作。</p></blockquote>

<h1>SQLite两种日志系统的比较</h1>


<p><p>
SQLite数据库管理系统原先采用的是“rollback journal”机制，而从SQLite的3.7.0版本开始采用最新的
“write-ahead logging”机制，该机制更大程度上支持数据库访问的并发，减少非必要的IO操作成本。
<p>
<li>“write-ahead logging”机制的优点</li>
<p>
1). WAL机制在大多数场景下比&#8221;rollback journal&#8221;机制更为高效。</br>
2). WAL机制提供了更加强的并发能力，读取操作不会阻塞写操作，写操作不会阻塞读取操作。读取操作和写操作可以并发的进行。</br>
3). WAL机制实现I/O操作更加顺序化。</br>
4). WAL机制使用fsync()函数频率降低，使得因为调用该系统调用导致崩溃的概率降低。</br>
</p>
<li>“write-ahead logging”机制的缺点</li>
<p>
1). WAL机制要求虚拟文件系统支持内存共享原语，在类Unix系统和Windows系统中内置提虚拟文件系统提供了该功能但其他文件系统并不一定支持。</br>
2). WAL机制要求所有使用该数据库的进程必须在同一台主机上，也就是SQLite数据库管理系统并支持网络文件系统。</br>
3). 多数据库参与的事务对各个数据库来说是原子的，但是对于所有的数据库集合来说不具备原子性。</br>
4). 使用WAL机制将无法设置数据库Page的大小，要设置数据库存储page的大小只能在&#8221;rollback journal&#8221;机制下。</br>
5). 使用WAL机制无法打开只读的SQLite数据库。</br>
6). WAL机制相对于传统的“rollback journal”机制在读操作频繁而写操作较少的程序内速度慢。</br>
7). WAL机制增加了ckeckpointing概念，在理论上该操作是原子性的但是开发人员必须了解这个问题。</br>
8). WAL机制对于小规模的事务效率比较好，但是对于大规模的事务效率并不好。在事务处理的数据量超过100M时使用传统的&#8221;rollback journal&#8221;比较
合适，在事务的数据量超过1GB时WAL机制将发生I/O操作失败或则磁盘满问题，在事务数据量操作有若干个MB时建议使用传统的“rollback journal”机制。
</p>
<h1>“write ahead logging”机制</h1>
<p>
在传统的“rollback journal”机制中，通过将数据库文件内的内容写入到称为“rollback journal”的独立文件中，再将改动的内容
写入到数据库文件中。在发生crash或则rollback时，将&#8221;rollback journal&#8221;文件内数据库原先的内容写回到数据库文件，将数据库
文件的内容恢复到原来的样子。事务的commit的标志是删除这个&#8221;rollback journal&#8221;文件。
</p>
<p>
最新的WAL机制则是与&#8221;rollback journal&#8221;相反，数据库文件内保存原来的数据，修改的数据写到一个称为WAL的文件，事务commit
的标志是一个特殊的记录指示内容写入到WAL文件。所以commit发生是数据可以没有写入到数据库文件，这就允许读操作读取数据库
文件内未变化的内容，写操作同时向WAL提交内容。一个WAL文件可以添加若干个事务。
</p>
<h2>检查点(checking point)</h2>
<p>
提交在WAL文件中的事务最后都要写到数据库文件内，将WAL文件内事务的内容提交到数据库文件内的操作称为检查点(checkpointing)。
从另外一个角度来看传统的&#8221;rollback journal&#8221;机制和“Write ahead Logging”机制的区别是传统的&#8221;rollback journal&#8221;机制存在两种
操作原语读操作和写操作，而&#8221;write-ahead logging&#8221;机制存在三种操作原语操作，他们分别是读操作、写操作和检查点操作。默认
情况下SQLite在WAL文件大小达到100页时将启动检查点操作，应用程序不需要为检查点触发操作进行任何设置操作，如果有需要可以
手动设置检查点触发的阈值或则关闭检查点自动触发开关，自己开启一个线程在合适的是否出发检查点操作。
</p>
<h2>并发</h2>
<p>
开启“Write-ahead logging”机制的SQLite数据库在读操作开始的时候，会记录最后一个有效的提交的位置，这个位置称为“end mark”。
由于在多个读操作存在的情况下，WAL文件可以继续增长、提交新记录，每个读数据库操作必须有一个独立的“end mark”。但是对于
每个读操作，在事务的整个生命周期内“end mark”都没有发生变化，这就保证了一个读事务只能看到在某个时刻的数据库内容。
</p>
<p>
在读操作需要整页的数据时，首先检查WAL文件内是否存在要求的那一页数据。如果WAL文件内存在要求的那一页数据，读操作将拉取WAL
文件内在&#8221;end mark&#8221;之前的那一页数据。如果在WAL文件内读操作的&#8221;end mark&#8221;之前没有要求的那一页数据，读操作将从数据库文件内
获取要求的那一页数据。读操作可能在不同的进程内，为了避免每个读操作都扫描整个WAL文件以获取要求的那页数据，在共享内存中
维护一个称为“wal-index”的数据结构，该数据结构提供快速定位WAL文件内的页，减少I/O操作次数的功能。“wal-index”的使用提高了
读操作的性能，但是使用共享内存意味着所有的读操作必须在同一个机器上，这就是为什么“write-ahead logging”机制无法在网络文件系统上正常工作。
</p>
<p>
写操作仅仅在WAL文件的尾部添加新内容。因为写操作不会干扰读操作，所以读操作和写操作可以同时进行操作，但由于只有一个WAL文件，
所以一次只能有一个写操作。检查点操作将WAL文件的内容拷贝到数据库文件，检查点操作可以与多个读操作并发的进行，但是在拷贝的内容
超过任何一个读操作的“end mark”时必须停止下来。检查点操作必须在该处停止因为超出“end mark”的内容拷贝到数据库文件将会覆盖掉当前
读操作读取的内容。检查点能够记录上次拷贝的最终位置，能够在下一次触发时将WAL文件的剩余的内容复制到数据库文件中。因此一个运行
时间很长的读取事务将阻塞检查点操作的进行，但是每个读取事务都会结束，这时检查点操作就可以继续下去。
</p>
<p>
无论什么时候，写操作都将检查检查点已经完成的进度，如果检查点操作将整个WAL文件的内容复制到数据库文件，同步完成了并且没有读
操作访问WAL文件，那么写操作会将WAL文件重定位到文件开始处，并将事务提交到WAL文件的开始处。这个机制很好的解决了WAL文件无限制
的增长问题。
</p>
<h2>性能</h2>
<p>
“write-ahead logging”机制的写操作事务只涉及到一次文件写操作，而“rollback-journal”机制的写操作事务却涉及到两次文件写操作并且
在&#8221;write-ahead logging&#8221;机制内所有的写操作都是按序进行的。此外，将数据同步到Disk也不是强制要求的，只要应用程序愿意在断电或则
重启情况后进行同步操作。
</p>
<p>
另一方面由于读操作需要检查WAL文件的内容，随着WAL文件大小的增长检查时间将会成比例增加。“wal-index”数据结构的存在使得查找WAL
文件的内容速度加快，但是随着WAL文件的增长性能也将下降。因此通过定时进行检查点操作控制WAL文件的大小对于维持良好的读取性能是
十分重要的。
</p>
<p>
检查点操作要求将内容同步到Disk上以避免在突然断电或则重启的情况下数据库发生崩溃。在将WAL文件的内容复制到数据库文件之前必须将
WAL的内容同步到DIsk上并且在重置WAL文件的内容时需要将数据库文件的内容同步到Disk上。检查点操作也需要进行多次文件定位操作，检查
点操作将尽最大可能将尽可能多的连续页复制到数据库文件中，但是尽管如此在复制多页数据还是需要多次文件定位操作，这些因素都将导致
检查点操作比写事务速度要慢。
</p>
<p>
SQLite默认的策略是在WAL文件达到100页大小之前，允许连续的写事务。而在WAL文件达到100页时将在接下来的每个commit时触发检查点操作
直到WAL文件的大小小于100页。默认情况下检查点操作将会自动在使WAL文件大小超过100页的事务提交的同一个线程内运行。这个策略导致了
大部分事务提交操作执行得很快而少量的事务提交将会变得比较慢。如果这个结果对于用户来说是比较难以接受的，那么可以关闭自动检查点
操作功能，在另一个线程或则进程周期性的执行检查点操作。
</p>
<p>
在很多时候需要在读操作性能和写操作性能之间进行权衡。为了尽可能提高读操作的性能希望将WAL文件的大小控制得尽可能小，为此希望尽
可能多的执行检查点操作甚至每次commit都执行一次检查点操作。为了尽可能提高写操作的性能，将检查点操作的开销分摊到尽可能多的写
操作上，也就会减少运行检查点的次数，在每次进行检查点操作时让WAL文件大小尽可能的变大。控制检查点执行的频率根据对读性能的要求
和写性能的要求不同而不同，默认的策略在WAL文件大小达到100个页时启动检查点操作在测试程序中允许良好，但是其他的策略可能在不同
的平台下运行的更好。
</p>
<h1>激活和配置WAL模式</h1>
<p>
数据库连接默认的模式设置为&#8221;DELETE&#8221;，如果要更改为WAL模式需要执行PRAGMA journal mode=WAL指令。journal mode指令返回的字符串指明
了当前的模式。如果模式设置成功将返回“wal”，如果重新设置模式失败将保持原来的模式并返回原来模式对应的字符串。
</p>
<h2>自动检查点</h2>
<p>
默认情况下，SQLite在导致WAL文件大小超过1000页的事务提交时或则数据库最后一个连接关闭时自动执行检查点操作，默认的配置在大多数
应用程序上工作良好，但是如果希望进行更为精细的控制，可以通过调用sqlite3 wal checkpoint()函数或则使用wal checkpoint pragma指令
强制执行一次检查点操作。可以通过调用sqlite3 wal autocheckpoint()函数或则使用wal autocheckpoint pragma指令更改自动执行检查点
操作的阈值和关闭自动执行检查点功能。在程序内也可以通过sqlite3 wal hook()函数注册一个钩子，在将事务提交到WAL时回调指定的函数，
在钩子函数中根据需要调用sqlite3 wal checkpoint() 函数和sqlite3 wal checkpoint v2()函数执行检查点操作。
</p>
<h2>应用程序初始化的检查点</h2>
<p>
应用程序可以通过在写数据库连接上调用sqlite3 wal checkpoint()函数或则sqlite3 wal checkout v2()函数来初始化一个检查点。根据
活跃程度的不同存在三种类型的检查点，PASSIVE、FULL和RESTART。默认的检查点类型是PASSIVE，该类型的检查点会在不干扰其他数据库
连接的情况下尽可能执行，在并发的读操作和写操作没有结束时不会停止。所有通过sqlite3 wal checkpoint()函数初始化和自动检查点
机制初始化的检查点的类型是PASSIVE。FULL和RESET类型的检查点只能通过sqlite3 wal checkpoint v2()函数初始化。
</p>
<h2>WAL模式的持久性</h2>
<p>
与其他的日志类型不同，PRAGMA journal mode=WAL的设置会延续下去，如果一个进程的数据库连接被设置成WAL模式，即使关闭重新打开数据库，
该数据库连接的日志模式还将维持WAL模式。如果一个进程将日志模式设置成RRUNCATE那么在关闭并重新打开数据库时将会恢复成DELETE模式而
不是先前设置的TRUNCATE模式。
</p></p>

<p><strong>WAL模式的延续性表明了应用程序无需进行任何改变就可以将日志更改为WAL模式，只需要使用shell或则其他工具在运行PRAGMA journal mode=WAL
指令并重启程序。WAL日志模式将会被设置到同一个数据库上的所有数据库连接。</strong>
<h1>WAL-INDEX共享内存的实现</h1>
<p>
wal-index是通过使用mmap()系统调用将一个普通文件映射到内存中实现的。先前的版本在实现WAL模式时使用诸如/dev/shm目录下的文件这类
可变的共享内存。这种实现的一个问题是拥有不同根目录的进程将会得到不同的文件，因此使用了不同的共享内存导致数据库崩溃。其他一些
创建匿名共享内存块在其他类型的类Unix系统上不具备可移植性，并且我们无法在Windows系统上找到创建匿名共享内存的办法。我们找到的
唯一办法是通过使用mmap()系统调用将数据库目录下的文件映射成为共享内存。
</p>
<p>
使用一个普通的disk文件来通过共享内存有一个缺点，将共享内存写回到disk产生不必要的I/O操作。但是开发者认为这不是一个主要的问题点，
因为wal-index数据结构很少超过32KB并且不会进行同步操作。此外wal-index对应的文件在最后一个数据库连接关闭时都会被删除掉，这将会
防止正真的I/O操作的发生。
</p>
<p>
程序如果多共享内存的默认实现无法接受则可以使用其他途径来实现共享内存。例如，如果一个数据库只会被一个进程内的多个线程访问，那么
wal-index的实现可以通过使用堆空间而不是真正的共享内存。
</p>
<h1>不使用wal-index实现WAL</h1>
<p>
在SQLite的3.7.4版本以后，在第一次数据库访问前将locking mode设置为EXCLUSIVE就可以创建、读写数据库而不需要共享内存。也就是说只要
保证只有一个进程访问数据库，就可以不使用共享内存。
</p>
<p>
如果在第一次访问WAL模式的数据库之前设置了EXCLUSIVE锁模式，那么SQLite数据库程序不会调用任何与共享内存有关的函数，也不会创建使用
共享内存的wal-index数据结构。在此情况下只要日志模式是WAL模式，数据库连接就会维持为EXCLUSIVE锁模式，任何试图通过PRAGMA locking mode=NORMAL；
指令来修改锁的模式都会无效。更改EXCLUSIVE模式的唯一途径是先将改掉WAL日志模式。
</p>
<p>
如果第一次访问WAL日志模式数据库的锁模式是NORMAL的话，那么共享内存的wal-index数据结构将会创建。这也就意味着虚拟文件系统必须支持
&ldquo;version 2&#8221;类型的共享内存。如果虚拟文件系统不支持共享内存，那么WAL模式下打开数据库或则将数据库日志模式切换成WAL模式都将失败。
只要有一个数据库连接使用共享内存的wal-index数据结构，数据库锁模式可以在NORMAL和EXCLUSIVE模式之间随意切换，
</p></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/08/androidkai-yuan-zu-jian-zhi-disklrucache/">Android开源组件之DiskLruCache</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-08T22:24:54+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>在Android应用程序开发过程中不可避免的要接触到内存数据Cache和外部存储介质数据的Cache。DiskLruCache
作为AOSP提供的一个外部存储介质数据的Cache，我们有必要对它进行深入的了解。</p></blockquote>

<p>
对一个开源组件的学习，首先必须掌握该组件最基本的使用方法。在熟练掌握基本使用方法后才能进一步根据组件
使用场景对组件的实现进行深入分析。本片博客将根据习惯，将从该组件的使用方法开始介绍，接下来将详细介绍
日志文件的格式，最后按照API的使用场景对组件的实现进行剖析。
</p>


<h1>DiskLruCache基本使用介绍</h1>


<p>
DiskLruCache做为外部存储介质的缓存，我们必须了解其基本的组成结构。DiskLruCache由一系列的entry组成，每
个entry对应与journal文件中的一行记录。而一个entry又是由若干个values组成，其实每个value代表着一个文件。
至于每个entry所拥有的文件个数则用户可以通过DiskLruCache的<code>open()</code>方法进行配置。
</p>


<p>
我们在进行编程的时候常用的是通过DiskLruCache的open()方法获得一个DiskLruCache实例（DiskLruCache的构造方
法是私有的）。在获取到DiskLruCache实例后，通过该类的edit()方法获取指定key对应的Editor进行读写操作或则
通过get()方法获取Snapshot实例进行批量的读操作。
</p>


<pre><code>final int appVersion = 1;
final int valueCount = 10;
final int maxSizeInByte = 1024 * 1024 * 100;
File cacheDir = new File(Environment.getExternalStorageDirectory(), "diskCache");
DiskLruCache cache = DiskLruCache.open(cacheDir, appVersion, valueCount, maxSizeInByte);
Editor editor = cache.edit("thumnail");
FileOutputStream fos = editor.newOutputStream(1);
.....
editor.commit();

FileInputStream fis = new FileInputStream(editorr.newInputStream(1));
.....
</code></pre>

<h1>DiskLruCache的journal文件格式介绍</h1>


<p>
在介绍DiskLruCache的journal文件格式之前，先了解一下DiskLruCache的文件构成，这有助于我们正确的理解journal
文件的格式。DiskLruCache所有的文件都在用户指定的一个目录内，该目录内包含了DiskLruCache管理所需的记录文件
也包含了存储数据的文件。
</p>


<h2>DiskLruCache管理所需的记录文件</h2>


<p>
其中DiskLruCache管理所需的记录文件包括这几个文件，journal文件、journal backup文件和journal tmp文件。其中
journal文件是这一部分着重需要说明的内容，其他两个文件的用途通过文件的名字可以很清楚的看出来。journal back
文件保存的是处于正确状态的journal文件的内容，一般情况下该文件是不存在的，只有在journal文件未成功更新到一
个新的状态值时才可能产生的。总的来说，这几个文件都是辅助journal文件从一个正确的状态切换到另一个正确的状态，
<img class="center" src="/images/rebuildJournal.png">
从上面的代码可以看出journal tmp文件是在rebuild journal文件时写入的数据的文件，该文件存储的是下一个正确状态
的值，journal backup文件是上一个状态journal文件的值。在journal tmp文件成功改为journal文件的时候会将backup
文件删除。
</p>


<h2>DiskLruCache保存数据的文件</h2>


<p>
DiskLruCache是由entry构成的，而每个entry又是由若干个value构成的。其中每个value对应着两个文件，一个文件称为
clean文件，另一个文件称为dirty文件。这里的dirty文件和clean文件的关系与journal文件和journal tmp文件类似，
dirty文件是用户写入数据的文件，只有用户确认提交写入的数据时才会将dirty文件更名为clean文件。在文件系统中这
两个文件的名字有着固定的模式，dirty文件的名字通常是key.index.tmp而clean文件的名字通常是key.index。也就是说
用户通过Editor的<code>newOutputStream()</code>获取的OutputStream写入的数据实际上是写到dirty文件内，只有用户
调用<code>commit()</code>方法时才会将dirty文件更名为clean文件。
</p>


<h2>Journal文件格式和记录格式</h2>


<h3>Journal文件格式</h3>


<p>
与其他一些常见格式的文件类似，DiskLruCache文件也存在文件头的概念。DiskLruCache文件头由五行数据组成，这五行
数据标识了DiskLruCache journal文件的身份。他们的顺序分别是MAGIC（libcore.io.DiskLruCache）、VERSION（DiskLruCache
的版本）、appVersion、valueCount（每个entry包含的value的个数）。
</p>


<p>
这些数据的构建在<code>rebuildJournal()</code>方法内，该方法在整个组件中有两处地方被调用。他们分别是在用户首次
使用该cache时调用<code>open()</code>方法，和组件定时整理Cache使用的空间时调用。这两处地方是：
<img class="center" src="/images/diskLruCacheOpen.png">
<img class="center" src="/images/cleanUpCallable.png">
</p>


<h3>Journal文件的记录格式</h3>


<p>
DiskLruCache的journal文件除了header部分以外，其他的内容中每一行都代表着cache中一个entry的记录信息。这里的记录
信息包括记录状态、键值和其他状态值组成（例如字节数）, 这些数据通过空格字符分割开来。记录状态和记录的键值必须
符合一定的规范，其中记录的状态包括固定的几个值CLEAN、READ、DIRTY和REMOVE，而键值则必须由0-9、a-z和下划线构成
的并且整个key的长度不得超过64个字符。
</p>


<p><li>DIRTY状态：</li></p>

<p>
DIRTY状态表明当前的entry处于被创建或则更新的状态。正常情况下每个DIRTY状态记录的下一个记录是CLEAN或则REMOVE活动。
如果一个DIRTY状态的记录缺乏配对的CLEAN或则REMOVE记录则表明value的dirty文件需要被删除掉！
</p>


<p><li>CLEAN状态：</li></p>

<p>
CLEAN状态表明对应的entry被成功的commit并且现在可以进行读操作。CLEAN记录中会包含entry每个value对应的长度。
</p>


<p><li>REMOVE状态：</li></p>

<p>
REMOVE状态表明该记录已经被删除了。
</p>


<p><li>READ状态</li></p>

<p>
READ状态记录了entry访问的频率。
</p>


<h1>DiskLruCache的API场景实现分析</h1>


<p>
这里我们从调用API的角度按程序的执行逻辑逐步分析DiskLruCache的实现原理。这里将划分为三条路径进行分析，这三条路径
分别为DiskLruCache调用<code>edit()</code>方法获取Editor、调用<code>get()</code>方法获取Snapshot和调用<code>remove
()</code>方法删除指定的entry。
</p>


<p><li>DiskLruCache的open()方法</li></p>

<p>
在以上三条执行路径中均包含DiskLruCache实例获取的操作，为此必须将DiskLruCache实例获取的代码的逻辑搞清楚。由于
DiskLruCache的构造方法是私有的，所以获取DiskLruCache实例必须通过<code>open()</code>方法获取。<code>open()</code>
方法需要正确处理journal文件和journal backup文件的关系，如果directory下存在journal backup文件则需要根据journal文件
是否存在进行journal文件的恢复或则journal backup文件的删除。在journal文件存在的情况下需要根据文件里面的信息构建
entry的Lru映射关系，如果journal文件不存在则需要根据内存里entry的信息rebuild一个Lru的映射表。
<img class="center" src="/images/DiskLruCacheOpen.png">
</p>


<p><li>DiskLruCache的edit()方法</li></p>

<p>
DiskLruCache的<code>edit()</code>方法的逻辑是根据传进来的key获取entry或则创建新的entry。如果无法获得entry对象则新
创建一个Entry实例，并将其currentEditor设置为新创建的Editor对象。如果可以获取到entry对象则判断其是否存在currentEditor
，如果存在该对象则说明该entry正在被访问当前请求无法满足。
<img class="center" src="/images/DiskLruCacheEdit.png">
</p>


<p><li>DiskLruCache的get()方法</li></p>

<p>
DiskLruCahe的<code>get()</code>方法获取Snapshot对象，利用该对象进行读操作。<code>get()</code>方法获取key对应的Entry
，创建一系列FileInputStream对象，该对象是value的clean文件的FileInputStream。在journal文件内添加一条READ状态的记录并
且创建一个Snapshot对象用于返回。
</p>


<p><img class="center" src="/images/DiskLruCacheGet.png">
<li>DiskLruCache的remove()方法</li></p>

<p>
DiskLruCache的<code>remove()</code>方法首先获得key对应的Entry，根据该Entry是否处于编辑状态进行控制。如果Entry处于编辑
状态那么不允许用户删除当前的Entry，否则删除该Entry的value对应的clean文件并重新计算DiskCache的size。如果成功删除该entry
的数据那么将在journal文件中添加一条REMOVE的记录。
<img class="center" src="/images/DiskLruCacheRemove.png">
</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/07/sqlite3wen-jian-suo-yu-bing-fa-kong-zhi/">SQLite3文件锁与并发控制</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-07T20:39:56+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>SQLite3数据库的文件锁机制与并发是一个很有趣话题，只有在深入了解SQLite3数据库文件锁的机制才能
在工作中快速解决多线程或则多进程并发引起的数据库锁问题。在本文档内并不涉及SQLite3WAL模式下的机制。</p></blockquote>

<h1>SQLite3文件锁与并发概述</h1>


<p>
相对于原来SQLite2，SQLite3引入了新的文件锁机制和日志机制，大大加强了SQLite数据库的并发能力减少了写“饥饿”现象的发生。
同时新的机制也实现了多个数据库文件事务提交的原子性。
</p>


<p>
锁和并发控制是由称为“pager”的模块来处理的，该模块负责SQLite数据库&#8221;ACID&#8221;的实现。该模块保证了所有的变化一次性全部发生，
这些变化要么全部发生或则全部不发生。保证多个线程或则进程不以不兼容的方式同时访问数据库，一旦变化提交将会一直存在直到
显式删除。
</p>


<p>
站在pager的角度来看，数据库是由一系列统一大小的块组成的文件，每个块大小是1024字节，这个块也被成为“page”(页)。文件内页是
从1开始计数，所以文件的头1024个字节为文件的第一页。&#8221;pager&#8221;模块高效的控制着多进程或则多线程对数据库文件的访问。
</p>


<h1>SQLite3文件锁状态</h1>


<p>
SQLite数据库主要由以下几种锁状态：
</p>


<p><li>UNLOCKED状态</li></p>

<p>
这时数据库没有处于锁状态，数据库可以进行读或则写。内部缓存的数据在使用之前必须通过校验，进程可以使用本进程内允许的锁对
数据库进行读或则写。
</p>


<p><li>SHARED状态</li></p>

<p>
这时数据库可以进行读操作但不能进行写操作。在同一时间内多个线程可以持有SHARED锁，所以可以有多个线程进行读操作。但是处于
该状态下不允许其他线程进行写操作。
</p>


<p><li>RESERVED状态</li></p>

<p>
RESERVED锁说明线程打算在将来的某个时间点进行写操作，但是目前正对数据库文件进行读操作。在同一时间点只允许一个RESERVED锁
的存在，但是允许多个SHARED锁与一个RESERVED锁同时存在。RESERVED锁与PENDING锁的区别是, RESERVED锁允许其他线程加SHARED锁。
</p>


<p><li>PENDING状态</li></p>

<p>
PENDING锁意味着持有该锁的进程希望尽快进行写操作，该进程在等待当前所有的SHARED锁的清除以便获取EXCLUSIVE锁。如果当前存在
PENDING锁那么不允许添加SHARED锁，但是已经处于激活状态的SHARED锁则允许继续存在以便结束读操作。
</p>


<p><li>EXCLUSIVE状态</li></p>

<p>
对数据库文件进行写操作时必须持有该锁，文件只允许一个EXCLUSIVE锁存在不允许其他任何锁的存在。为了最大程度的并发，SQLite实
现了EXCLUSICE锁持有时间的最小化。
</p>


<p><em>操作系统层面负责跟踪上述几种锁状态，而&#8221;pager&#8221;模块则只能感知到以上五种中的四种，PENDING锁状态是
获取EXCLUSIVE锁的中间时过程所以“pager”模块并不会跟踪PENDING锁状态。</em></br></p>

<h1>回滚日志</h1>


<p>
当进程想要进行写操作时，首先会将数据库文件中为变化的内容写到日志文件内。回滚日志文件是一个普通的磁盘文件，通常和数据库文
件处在同一个目录中，并且文件名字是数据库文件名加&#8221;-journal&#8221;后缀。回滚日志文件同时也记录原来数据库文件的大小以便随着数据库
文件的增长能够恢复到原来的大小。
</p>


<p>
如果存在多个数据库文件，那么每个数据库都会有一个自己的日志文件。一般还会有一个称为“master”（主）的日志文件。“master”日志
文件不包含任何页内的数据，而是包含各个数据库对应的日志文件名字。每个数据库对应的日志文件内也包含“master”日志文件的名字。
如果只有一个数据库（或则当前事务中只有没有其他数据库参与），那么不会创建“master”日志文件并且在数据库对应的日志文件中存放
“master”日志文件名字的位置存放一个空字符串。
</p>


<p>
为了数据库数据的完整性而需要回滚，回滚用到的日志文件称为热点日志文件。在进程更新数据库的过程中由于程序崩溃、操作系统崩溃
或则系统掉电而无法完成更新时将会创建一个热点日志文件。热点日志文件的出现标志着异常情况的发生，热点日志文件的存在是为了从
崩溃和掉电导致的异常状况下恢复数据。如果整个数据更新过程中没有发生任何异常情况，那么将不会出现热点日志文件。
</p>


<p>
判断一个日志文件是否是热点日志文件的步骤：</br>
1). 日志文件存在并且它的大小超过512字节。</br>
2). 日志文件的头部大小非零并且组织良好</br>
3). “master”日志文件存在或则“master”日志文件名字为空</br>
4). 日志文件对应的数据库文件没有RESERVED锁。
</p>


<h2>日志文件的处理机制</h2>


<p>
在读取数据库文件的内容之前，SQLite都会检查是否存在热点日志文件。如果存在热点日志文件，那么在读操作之前将使用该热点日志文件
恢复数据，这样就保证了在读的时候数据是一致的。
</p>


<p>
进程从数据库文件的读操作的步骤：</br>
1). 打开数据库文件并且申请获取SHARED锁，如果无法获得SHARED锁那么直接失败并且返回SQLITE_BUSY。</br>
2). 检查数据库文件是否存在对应的热点日志文件，如果没有对应的热点日志文件那么该步骤结束。如果存在热点日志文件，那么必须按照
以下的步骤进行回滚。</br>
3).申请获取PENDING锁，如果申请失败那么表明有其他进程在进行回滚操作，在这种情况下只要释放所有的锁，关闭数据库并且返回SQLITE_BUSY。</br> 
4). 读取日志文件并且回滚这些变化。</br>
5). 等待这些回滚变化持久化。</br>
6). 删除日志文件。</br>
7). 删除“master”日志文件，该步骤是可选的。</br>
8). 删除EXCLUSIVE和PENDING锁，保持SHARED锁。
</p>


<h2>删除过时的“master”日志文件</h2>


<p>
没有强制的要求删除过时的“master”日志文件，唯一的目的是释放其占用的磁盘空间。没有一个日志文件指向该“master”日志文件，那么该
“master”日志文件称为过期的日志文件。为了甄别“master”日志文件是过时的日志文件，首先通过读取该“master”日志文件获取它记录的所有
日志文件。接下来检查每个日志文件，查看这些日志文件中有没有指向该“master”日志文件的。这些日志文件中一旦有一个日志文件指向该
“master”日志文件，那么该“master”日志文件就不是过时的“master”日志文件了。如果这些能找到的日志文件中没有一个指向该“master”日志
文件那么该“master”日志文件可以断定为过时的“master”日志文件。
</p>


<h1>SQLite写入操作</h1>


<p>
在向数据库文件写入数据之前，进程必须先获取SHARED锁。在获得SHARED锁后必须在申请获取RESERVED锁。RESERVED锁标志着进程想要在将来
的某个时刻向数据库文件写入数据。一次只能允许一个进程获取RESERVED锁，在获得该锁后仍然允许其他进程读取数据。
</p>


<p>
如果进程在获取RESERVED锁失败，那表明有其他进程已经获得了RESERVED锁。在这种情况下，写操作将失败并且返回SQLITE_BUSY。
</p>




<p>
在成功获得RESERVED锁，进程会创建回滚日志。日志文件的头部在初始化时候保存数据库文件的大小，并且日志文件的头部会保留存储master日志
名字的空间。
</p>


<p>
进程在正式修改数据库文件之前，需要将数据库文件内的内容写入到日志文件。数据库变动的内容开始时只保存在内存中，数据库文件保存不变，只
有这样其他进程依然可以读数据库文件的内容。
</p>


<p>
在内存缓存充满或则准备好提交修改的数据时写进程才会更新数据库文件。在更新数据库文件之前，必须保证没有其他进程在读取数据库内容并且
日志文件的内容已经安全的存放在磁盘上以便在断电发生后可以用来回滚未完成的提交。
</p>




<p>
具体步骤如下：</br>
1). 确保所有的日志文件内容都成功写入到磁盘，防止在断电情况下丢失数据。</br>
2). 获得一个PENDING锁，再获得EXCLUSIVE锁。如果其他进程持有SHARED锁，写进程必须等待其他进程释放持有的SHARED锁才能获得EXCLUSICE锁。</br>
3). 将内存中存放的关于页数据的修改内容写入到磁盘内。 
</p>




<p>
如果内存缓存空间已满，那么写进程将会立刻提交修改的内容到磁盘上，否则写进程依然在使用内存缓存其他页数据的变化。为了将下一次的数据修改
写入到数据库文件，日志文件需要同步到磁盘上。写进程在所有的变化提交之前必须一直持有EXCLUSIVE锁，这也就说在开始提交数据变化到提交结束这
段时间内其他进程不允许访问数据库。
</p>




<p>
4). 持有数据库文件的EXCLUSIVE锁，确保所有内存中数据的修改点通过以上三个步骤都写入到数据库文件中。</br>
5). 刷新所有的数据库变化到磁盘，等待所有的变化实际写入到磁盘上。</br>
6). 删除日志文件。</br>
7). 释放进程持有的EXCLUSIVE和PENDING锁。</br>
</p>


<p>只要写进程释放PENDING锁，其他进程可以读取数据库内容，在当前的实现中，RESERVED锁也会被释放。</p>


<p>
如果事物涉及到几个数据库文件，那么提交流程将更为复杂：</br>
1). 确保对所有数据库文件都持有一个EXCLUSIVE锁和每一个数据库文件都有一个有效的日志文件。</br>
2). 创建一个master日志文件，master日志文件的名字可以是随意的。将没有日志文件的名字写到master日志文件内，并将其刷新到磁盘上。</br>
3). 将master日志文件的名字写到各个日志文件内，并将日志文件的内容同步到磁盘上。</br>
4). 将内存中所有关于数据库变化的内容刷新到磁盘中。</br>
5). 删除master日志文件。</br>
6). 删除其他日志文件。</br>
7). 释放所有持有的EXCLUSICE锁和PENDING锁。
</p>


<h1>写饥饿现象</h1>


<p>
在SQLite2版本上，如果有很多进程需要读数据库，可能会发生在一段很长时间内进程都在读数据库。在一段时间之内始终都有读锁存在，那么没有
进程那些修改数据库的内容，因为写进程无法获得写锁。
</p>


<p>
SQLite3版本通过PENDING锁避免写饥饿现象的发生，PENDING锁允许正在读的进程继续读操作但阻止其他进程获得读锁。所以读写频繁的数据库可以
使用PENDING锁避免写饥饿现象的发生。
</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/06/shellming-ling-zhi-ci-pan-fen-qu/">Shell命令之磁盘分区</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-06T23:13:26+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>
在Linux上我们经常进行磁盘管理，磁盘管理是系统管理者比较重要的内容。在系统上增加一块磁盘时一般的步骤是先对
磁盘进行分区建立可用的分区、对新建的磁盘分区进行格式化创建可用的文件系统、对刚建立好的文件系统进行检验最后
在系统上创建挂载点并将其挂载起来。
</p>


<p>
fdisk命令的具体用法如下：
</p>


<p>          <br/>
    fdisk   [-l]    设备名称</br>
        -l  在-l后面不带参数时将整个系统内的设备分区罗列出来，如果输入设备名称则将该设备上的分区
            信息罗列出来</p>

<pre><code>    例子：       $ sudo -s               &lt;&lt;== 切换到超级用户
                # df /                  &lt;&lt;== 查看根目录所在的磁盘
                # fdisk -l /dev/sda     &lt;&lt;== 查看/dev/sda设备的分区情况
                # fdisk /dev/sda        &lt;&lt;== 进入设备/dev/sda的交互模式
</code></pre>

<p>
在fdisk的交互模式中可以进行分区的添加、删除操作。在该模式里面有几个常用的命令如p查看设备的分区情况、d为删除
一个分区、n为新增一个分区、q为退出模式并不保存分区设置和w为退出模式并保存分区设置。
</p>


<pre><code>例子：       
        1. 删除分区：  
                        # fdisk /dev/sda    &lt;&lt;== 进入设备/dev/sda的设置模式
                        # p                 &lt;&lt;== 显示设备/dev/sda上的分区情况
                        # d                 &lt;&lt;== 删除/dev/sda上的分区，系统将提示输入待删除分区
                                             的号码删除9代表删除/dev/sda9分区
                        # q                 &lt;&lt;== 离开并且不保存刚才的分区设置

        2. 添加分区：   
                        # fdisk /dev/sda    &lt;&lt;== 进入设备/dev/sda的设置模式
                        # p                 &lt;&lt;== 查看设备/dev/sda的分区情况
                        # d                 &lt;&lt;== 删除/dev/sda上的分区，在这里将所有的分区删除
                        # n                 &lt;&lt;== 新建一个设备分区，系统将要求输入分区的类型。
                        ：p                --&gt; primary partition   新建的主分区
                          e                 --&gt; extended partition  新建的是扩展分区
                          l                 --&gt; logical partition   新间的是逻分区

                        : 设置分区号（例如1-4的数字等等）
                        : 设置起始柱面号
                        : 结束柱面号，可以手动输入结束柱面号或则(+#G|M|K)指定分区大小
                            # p                 &lt;&lt;== 查看分区设置结果
                            # q                 &lt;&lt;== 离开并不保存刚才设置的分区信息
</code></pre>

<p>
在这里必须注意的是fdisk只能在root用户下进行分区的设置。在新建分区时系统将提示我们设置新分区的类型，而分区类型无非
是主分区、扩展分区和逻辑分区。
</p>


<p>
系统提示的分区规则如下：</br>
<li>1.  1-4号分区尚未分配出去，并且系统没有扩展分区。这时将提示你选择主分区或则扩展分区。</li>
<li>2.  1-4号分区尚为分配出去，并且系统存在扩展分区。这时将提示你选择主分区或则逻辑分区。</li>
<li>3.  1-4号分区已经分配出去，系统将直接选择进行逻分区的创建。</li>
</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/06/shellming-ling-zhi-wen-jian-lian-jie/">Shell命令之文件链接</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-06T00:12:51+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>系统上文件链接有点儿恼人，经常无法正常解释它们的区别！好吧，其实理解了他们的原理那么他们也没那么容易混淆了！</p></blockquote>

<p><p>在Linux系统上存在这两种文件链接方式，他们分别是硬链接和软链接，其中软链接也称为符号链接。其实硬链接和
软链接之间还是存在不少差别，由于硬链接存在着一些限制，相对来讲软链接的使用范围更广一些。硬链接不能跨文件系统
而符号链接却没有这个限制，同时硬链接无法实现对目录的链接。这些限制都大大的降低了硬链接的使用范围。
<p>
<li>硬链接：</li> <br/>
<p>硬链接的本质并非是创建一个新的文件，而是在目录中添加了一个链接文件名，该链接文件名指向被链接文件的inode节点。
所以在使用ls命令查看链接文件和被链接的文件将会发现，他们的文件属性、权限和链接情况一模一样。在删除硬链接文件时
只有在被链接文件对应的inode中记录的链接数量为1时才会真正删除文件。
</p>
硬链接存在的限制为： 无法在不同文件系统中创建硬链接、无法为目录创建硬链接。</p>

<p><li>符号链接：</li>  <br/>
<p>
符号链接的原理与Windows下的快捷方式有些相似，符号链接可是真真切切的创建一个链接文件。这个链接文件有自己的inode
节点和磁盘数据块。不过这个链接文件的数据内容仅仅是存放被链接文件的路径，在用户访问链接文件时转向为对被链接文件
的访问。所以，用户将被链接文件删除后，将无法打开链接文件。使用ls命令查看链接文件和被链接文件可以发现他们的
inode节点是不一样的。
</p></p>

<p><p>创建链接命令：
ln  [-sf] 被链接文件 链接文件<br/>
-s 创建符号链接<br/>
-f 链接文件名已经存在，将其删除在创建链接文件<br/>
</p></p>

<pre><code>例子：   $ cp /tmp       &lt;&lt;== 进入tmp目录  
        $ cp /etc/manpath.config .  &lt;&lt;== 将etc目录下的manpath.config拷贝到当前目录  
        $ ln manpath.config manpath_hl.config   &lt;&lt;== 创建硬链接manpath_hl.config  
        $ rm -f manpath.config                  &lt;&lt;== 删除被链接文件，硬链接文件依然存在
        $ cat manpath.config                    &lt;&lt;== 可以查看文件内容，文件并未被真正删除  
        $ rm -f manpath_hl.config               &lt;&lt;== 删除硬链接文件  
        $ 
        $ cp /etc/manpath.config .
        $ ln -s manpath.config manpath_sl.config    &lt;&lt;== 创建符号链接文件manpath_sl.config  
        $ cat manpath_sl.config                     &lt;&lt;== 可以看到文件内容
        $ rm -f manpath.config                      &lt;&lt;== 删除被链接文件  
        $ cat manpath_sl.config                     &lt;&lt;== 无法读取文件
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/05/shellming-ling-zhi-bei-fen-yu-hui-fu/">Shell命令之备份与恢复</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-05T23:58:38+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>备份是生活中比不可少的操作，如果在灾难发生时没有必要的备份那你将会欲哭无泪。Linux系统的Shell提供了强有力
的备份工具dump,为此我们有必要来了解一下这个很酷的小伙子。@@</p></blockquote>

<p>
Linux上有个强大的备份工具，那就是使用dump命令。dump命令的功能十分强大，该命令不仅可以备份整个文件系统而且
还可以备份指定的目录。不过dump命令在备份目录时存在一定的限制，那就是只能完整的备份整个目录，无法制定等级
进行备份。
</p>


<p>
下面将具体介绍使用dump进行文件系统备份和目录备份，以及他们的区别：  
</p>


<p><li>使用dump命令备份整个文件系统：</li></p>

<p>
使用dump命令备份整个文件系统时可以制定等级进行备份，也就是说我们可以在第一次备份指定文件系统时进行完整备份，
在以后对同一个文件系统进行备份时只需要备份当前文件系统与以前备份之间差异就可以。这样就可以大大减轻备份文件
对系统空间的使用量。
</p>


<pre><code>                    dump    [-Suvj#] [-f 生成的备份文件]  待备份文件  
                            -S 查看备份指定文件需要的磁盘空间  
                            -u 将本次进行备份的时间记录到/etc/dumpdates文件内  
                            -v 查看dump备份过程中的信息  
                            -# #代表数字0到9，这个参数一般在制定等级备份时使用  
                            -f 备份产生的文件名称  

                    dump -W &lt;&lt;== 该命令查看/etc/fstab内具有dump设置的分区是否备份过

                    例子：   $ df -h &lt;&lt;== 找出最小的文件系统进行备份处理
                            $ dump -0vj -f root.dump0 /     &lt;&lt;== 对root目录进行备份, 在这里
                                                                 root目录是一个文件系统  
                            $ touch new_file.txt            &lt;&lt;== 在根目录下新建一个文件  
                            $ dump -1vj -f root.dump1 /     &lt;&lt;== 制定等级进行备份  
</code></pre>

<p><li>使用dump命令备份指定目录：</li></p>

<p>
使用dump命令备份目录存在一定的限制，例如无法使用-u、-#参数并且所有的备份数据必须在该目录下。  
</p>


<pre><code>                    dump    [-Svj] [-f 生成的备份文件]   待备份文件  
                            -S  查看备份指定文件需要的磁盘空间  
                            -v  显示备份过程中的信息  
                            -j  数据使用bzip2进行压缩  
                            -f  备份产生的文件名字  

                    例子：   $ dump -S /etc  &lt;&lt;== 查看备份etc目录所需的磁盘空间  
                            $ dump -0vj -f etc.dump /etc    &lt;&lt;== 对etc目录进行压缩备份  
</code></pre>

<p><li>使用restore命令进行恢复操作：</li></p>

<pre><code>    restore用法：            restore -t [-f dumpfile] [-h]   &lt;&lt;== 查看dump文件  
                            restore -C [-f dumpfile] [-D 挂载点] &lt;&lt;== 比较dump与实际文件  
                            restore -i [-f dumpfile]                &lt;&lt;== 进入互动模式，可以  
                                                                         进行部分文件还原  
                            restore -r [-f dumpfile]        &lt;&lt;== 还原整个文件系统  

                            其中-i一般进行目录的还原，而-r一般是进行文件系统的还原, -D参数表示  
                        查看挂载点与dump内的不同文件  

    例子：       $ restore -t -f etc.dump        &lt;&lt;== 查看etc.dump内备份含有的数据  
                $ restore -i -f etc.dump        &lt;&lt;== 进入交互模式可以对目录进行部分还原   
</code></pre>

<p>
其中restore的交互模式中可以使用add file、delete file和extract进行部分文件恢复的添加、删除和最终执行恢复操作。  
</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/05/androidshe-bei-rooting/">Android设备Rooting</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-05T23:51:48+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>Android设备的Rooting的比较常用的操作，Rooting的目的是取得目标设备上的超级用户权限。一旦拥有超级用户
权限可以进行很多令人惊奇的操作。为此有必要了解一下Android设备的存储分区，启动过程和历史上一些Rooting
的原理。</p></blockquote>

<h1>Android设备存储分区</h1>


<p>
存储分区是Android设备的逻辑存储单元，存储布局包括各种分区在存储器上排列顺序、偏移量和大小等内容。存储
布局通常是由Boot Loader进行处理，但也有一部分设备是由Android系统的Kernel进行处理。各个设备厂商的存储器
分区布局一般是不同的，但是Android设备一部分存储分区必须是固定的。
</p>


<h2>Android设备NAND FLASH分区</h2>


<p>Android设备的NAND FLASH必须遵循特定的分区布局，他们的布局如下：
<li>
boot loader分区: 该分区存储设备的Boot loader程序，boot loader程序用来初始化设备硬件、启动系统Kernel和实
现一些特定到启动模式
</li>
<li>
Splash分区： 该分区存储设备的启动时显示的图片，但一部分设备厂商将启动图片设置在boot loader程序内所以
这个分区可能没有。
</li>
<li>
boot分区： 该分区存放Android系统启动镜像，包括Android系统的Kernel(zImage)和根文件系统。
</li>
<li>
recovery分区： 该分区存放简化的Android系统启动镜像，该镜像仅仅包含Kernel镜像和recovery根文件系统。
</li>
<li>
system分区：该分区保存Android系统镜像，系统镜像包括Framework、libraries(库)、系统可执行程序和设备预装
程序。该分区将挂载到设备系统上的“/system”目录。
</li>
<li>
userdata分区：该分区也被称为数据分区，设备上应用程序的数据以及文件等将保存在该分区上，在启动后的设备上
该分区将被挂载到“/data”目录上。
</li>
<li>
cache分区：该分区存诸如recover日志文件，packages更新文件等放实用文件。如果设备将packages安装在SD卡上将
在分区内创建一个dalvik-cache目录。
</li>
<li>
radio分区：该分区存放基带镜像。
</li></p>

<h2>设备分区查看</h2>


<p>
可以使用cat命令查看“/proc/partitions”查看设备的分区情况，也可以查看/dev/block/platform/目录下的“by-name”
目录内的文件。
</p>


<p>
以下是在Google Nexus4设备（Android4.4系统）上查看“partition”情况：</br>
<img class="center" src="/images/android_proc_partitions.png" title="" >
</p>


<p>
以下是查看“by-name”目录内文件情况Google Nexus4：</br>
<img class="center" src="/images/android-dev-block-by-name.png">
</p>




<h1>Android设备启动过程概述</h1>


<p>
设备开启最先运行的程序是Boot Loader，该程序一般是由设备厂商提供的。Boot loader程序的功能一般是初始化底层
硬件，包括RAM存储、系统时钟和启动媒体等。Boot Loader同时为加载recovery镜像和设置设备进入下载模式提供支持。
</p>


<p>
在Boot Loader初始化好设备硬件后将Android系统的Kernel从外设boot分区加载到RAM中，接下来将执行控制权交给Android
系统的Kernel。Android内核将为系统初始化各种运行条件，启动各种系统运行所必须的系统服务等。这些包括内存初始化，
内存保护初始化、中断处理程序初始化、加载设备驱动程序等。最后内核将挂载根文件系统、启动“init”进程，“init”进程
是用户空间内所有进程的父进程。“init”进程通过解析“init.rc”和&#8221;init_hw_.rc&#8221;配置脚本启动用户空间内的各种系统服务
和组件。“init”进程启动的进程包括Android Debug Bridge守护进程、Zygote进程初始化Java运行环境，SystemServer进程
等。在SystemServer进程内的ActivityManagerService的<code>systemReady()</code>方法内将发送“ACTION_BOOT_COMPLETED”
广播等。
</p>


<h2>进入下载模式</h2>


<p>
当设备处于下载模式时我们可以修改外围存储设备内容，包括擦除设备的分区、执行另一个内核镜像等。擦除操作一般可以
通过“fastboot”协议实现，各个设备厂商使用的协议可能不同。各个设备进入下载模式的按键操作不太一样，这是有设备的
Boot Loader程序决定的。
</p>


<p>
例如Google Nexus4设备需要在设备关机时同时按下音量减小键和启动键，该设备的下载模式显示如下：</br>
</p>


<p><img class="center" src="/images/google_nexus4_download_mode.png"></p>

<h1>BootLoaders加锁与解锁</h1>


<p>
加锁的Boot Loader限制用户修改设备的固件，这些限制大多数是通过加密签名验证限制用户启动或则刷未经过认证的程序
到设备上。Google Nexus系列设备的Boot Loader默认是锁定的，如果用户希望运行一个定制的内核、recovery镜像或则操作
系统镜像那么必须先将Boot Loader解锁。各个设备厂商针对各自不同型号的设备提供不同解锁Boot Loader的方法，大多数
是设置设备进入FastBoot模式然后使用Android SDK提供的“fastboot”程序运行<code>fastboot oem unlock</code>命令。
</p>


<p>
一个Android设备的Boot Loader一旦解锁就会带来安全问题，如果你的设备丢失那么攻击者可以通过向你的设备刷入定制的
recovery镜像就可以访问设备上的所有数据包括Google账户、联系人等等。
</p>




<h2>Stock Recovery镜像和Custom Recovery镜像</h2>


<p>
Android的recovery系统负责在不擦除用户数据的情况下更新整个系统预装的应用程序的功能。Recovery除了支持OTA更新外也
支持擦除用户数据和cache分区。Recovery镜像存放在设备的recovery分区，该镜像文件仅仅包含最小的Linux镜像用于实现通
过物理按钮控制功能。用户可以通过使用物理按键的特定组合进入recovery模式或则通过adb程序的reboot recovery命令进入
Recovery模式。
</p>


<p>
    Stock recovery镜像是Android开发主分支上的，他一般需要保持前后的兼容性。而Custom Recovery镜像（定制的
Recovery镜像）很多，一般修改内容/br>
</p>


<p><li>选择性的挂载特定的分区</li>
<li>使用USB访问SD或则NAND FLASH分区</li>
<li>提供adb访问，adbd以超级用户运行</li>
<li>包含完全的备份和恢复功能</li></p>

<h1>Boot Loader解锁状态下的Rooting</h1>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/05/java-virtual-machinela-ji-shou-ji-qi/">Java Virtual Machine垃圾收集器</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-05T23:47:34+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>垃圾收集器是虚拟机内存回收的具体实现，不同Java虚拟机的垃圾收集器存在很大的区别。用户甚至可以组合各个年代所使用的垃圾收集器。</p></blockquote>

<p>
    接下来将分别列出常见的几个垃圾收集器原理以及他们的特点。`
</p>


<h1>Serial收集器</h1>


<p>
Serial收集器是历史最为悠久的垃圾收集器，这个收集器是一个单线程的垃圾收集器。该收集器不仅仅只会使用一个CPU或则一个线程去进行
垃圾收集工作，在他进行垃圾收集操作时必须暂停其他所有的工作线程。
</p>


<p>
Serial收集器的特点是简单而且高效，对于限定单个CPU环境时，Serial收集器由于没有线程交互的开销，可以获得最高的单线程收集效率。
Serial收集器是Client模式下虚拟机收集器的一个很好的选择。
</p>




<h1>ParNew收集器</h1>


<p>
ParNew收集器与Serial收集器的不同之处是ParNew收集器采用多线程进行垃圾收集操作，该收集器是Server模式下虚拟机中首选的新生代收集器。
在单CPU环境下ParNew收集器由于线程交互的开销，效果没有Serial收集器理想。
</p>


<p><strong>并行</strong>：<em>垃圾收集线程并行工作，而用户线程处于等待状态。</em></br>
<strong>并发</strong>: <em>用户线程和垃圾收集线程同时执行，用户程序在继续运行而垃圾收集程序运行在另一个CPU上。</em></p>

<h1>Parallel Scavenge收集器</h1>


<p>
    Parallel Scavenge收集器是一个新生代垃圾收集器，使用复制算法进行新生代的垃圾收集。同时Parallel Scavenge收集器也是个并行的
多线程收集器。Parallel Scavenge收集器的目标是达到一个可控制的吞吐量，吞吐量高可以高效率的利用CPU时间尽快完成程序运算任务，
主要适合在后台运算而不需要交互的任务。
</p>


<p>
Parallel Scavenge收集器提供两个参数-XX:MaxGCPauseMillis参数和-XX:GCTimeRatio参数设置最大垃圾收集停顿时间和设置吞吐量大小。
MaxGCpauseMillis参数可以设置为大于0的毫秒数，收集器将尽可能保证内存回收的时间不超过设定的值。GCTimeRatio参数的值是大于0且小于
100的整数，该参数设置的值是吞吐量的倒数。
</p>


<p><strong>吞吐量</strong></br>
<em>吞吐量是指CPU运行用户代码的时间与CPU消耗时间的比值，吞吐量=运行用户代码时间/（运行用户代码时间 + 垃圾收集时间）。</em></p>

<h1>Serial Old收集器</h1>


<p>
Serial Old收集器是老年代版本，他同样是一个单线程收集器，他使用“标记-整理”算法，这个收集器一般在Client模式下的虚拟机中使用。
</p>


<p>
该垃圾收集器在Server模式下的两大用途：</br>
1). 在JDK1.5之前的版本与Parallel Scavenge收集器配合使用，Parallel Scavenge垃圾收集器负责新生代垃圾收集，而Serial Old负责老年
代的垃圾收集。</br>
2). 作为CMS垃圾收集器在并发收集时Concurrent Mode Failure时使用的后备垃圾收集器。
</p>




<h1>Parallel Old收集器</h1>


<p>
    Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程“标记-整理”算法。在Parallel Old收集器出现之前，新生代
垃圾收集器Parallel Scavenge只能与老年代的Serial Old收集器配合使用导致在Server端整体吞吐量不高。在Parallel Old收集器出现后可以
和Parallel Scavenge收集器配合使用提供吞吐量。
</p>




<h1>CMS收集器</h1>


<p>
CMS收集器是一款以获取最短停顿时间为目标的收集器，该收集器是基于“标记-整理”算法实现，它的运作过程中包括四个过程。他们分别是“初始
标记”、“并发标记”、“重新标记”和“并发清除”四个阶段。其中“初始标记”、“重新标记”两个阶段需要“Stop The World”。“初始标记”仅仅是标记
一下GC Root能直接关联到的对象，“并发标记”就是进行GC RootsTracing过程，而“重新标记”则是为了修正并发标记期间用户程序继续运行而导致
标记产生变动的那一部分对象标记记录。
</p>


<p><p>
CMS垃圾收集器的明显缺点：</br>
1). CMS收集器对CPU资源十分敏感，在并发阶段不会导致用户线程停顿，但是会占用一部分线程而导致应用程序变慢，总吞吐量下降。</br>
2). CMS收集器无法处理浮动垃圾，可能出现一次&#8221;Concurrent Mode Failure&#8221;失败而导致一次Full GC的产生。浮动垃圾就是CMS在“并发清理”阶段
由于用户线程还在运行，产生新垃圾。而这部分垃圾在标记过程之后，CMS无法在单次收集中处理他们，只好留到下一次GC时清理掉。</br>
3). CMS收集器基于“标记-清除”算法思想，而这意味着垃圾收集结束后会产生大量的空间碎片。
<p></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/05/java-virtual-machinenei-cun-fen-pei/">Java Virtual Machine内存分配</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-05T23:44:35+08:00" pubdate data-updated="true"></time>
        
      </p>
    
  </header>


  <div class="entry-content"><blockquote><p>Java虚拟机内存管理的两个方面是对象内存的分配和对象内存的回收，在之前的笔记中已经记录
了Java虚拟机的对象内存回收方面的基本内容。</p></blockquote>

<p>
    对象的分配主要是在Java虚拟机的堆空间进行分配，一般是分配在新生代的Eden区上，如果启动了本地线程
分配缓存，将按线程分配在TLAB上，少数情况下也可能分配在老年代上。
</p>


<h1>对象分配在Eden区上</h1>


<p>
在大多数情况下，对象在新生代Eden区分配，在Eden区没有足够的空间时虚拟机将进行一次Minor GC。在发生Minor
GC时如果Survivor没有足够的空间容纳Eden区没有被回收的对象时将直接分配到老年代。
<li>Minor GC</li>
<p>Minor GC是新生代垃圾收集动作，在新生代的Java对象大都具有朝生夕死的特点，所以Minor GC发生比较频繁。</p>
<li>Major GC</li>
<p>Major GC是老年代发生的垃圾收集动作，在老年代垃圾收集动作发生时一般伴随至少一次的Minor GC。</p>
</p>


<h1>大对象进入老年代</h1>


<p>
Java大对象指需要连续大量内存空间的Java对象，大对象容易导致内存还有不少空间时就提前触发垃圾收集来获得足够的空间
来容纳他们。Java虚拟机提供参数&#8221;-XX:PretenureSizeThreshold&#8221;指明当对象所需的内存空间大于这个值时将直接在老年代分
配。
</p>


<h1>长期存活的对象进入老年代</h1>


<p>
虚拟机给每个对象定义一个对象年龄计数器，如果对象在Eden区出生并经过第一次Minor GC后仍然存活并且能够被Survivor容纳
的话，将被移动到Survivor并且对象年龄设置为1。对象在Survivor中内经历一次Minor GC，对象年龄计数器加一，在对象年龄
计数器值到一定值时将移动到老年代。
</p>


<h1>动态对象年龄判定</h1>


<p>
如果Survivor空间中相同年龄的所有对象大小总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，
无需等到MaxTenuringThreshold中要求的年龄。
</p>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="2">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/01/13/picassoyuan-ma-jie-xi-zhi-cache/">Picasso源码解析之Cache</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/01/12/sqlite3zhi-writeaheadlogging/">SQLite3之WriteAheadLogging</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/01/08/androidkai-yuan-zu-jian-zhi-disklrucache/">Android开源组件之DiskLruCache</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/07/sqlite3wen-jian-suo-yu-bing-fa-kong-zhi/">SQLite3文件锁与并发控制</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/06/shellming-ling-zhi-ci-pan-fen-qu/">Shell命令之磁盘分区</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - TuomingZheng -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
  - <span class="credit">Theme by <a href="http://www.gehaxelt.in">Gehaxelt</a></span>
  <span class="credit">and <a href="http://www.it-solutions-neef.de">IT Solutions Neef</a></span>
</p>

</footer>
  











</body>
</html>
